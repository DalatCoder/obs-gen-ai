## Ghi Chú Học Tập: Các Loại Hại Từ Việc Sử Dụng AI Không Có Trách Nhiệm

## Giới Hạn Thiên Kiến, Trôi Dạt Và Không Chính Xác Trong Mô Hình AI

- Để hạn chế thiên kiến (biases), trôi dạt (drift) và sự không chính xác (inaccuracies), mô hình AI cần con người can thiệp, chẳng hạn như huấn luyện lại trên bộ dữ liệu đa dạng hơn và tinh chỉnh thường xuyên.
    
- Con người phải xem xét các hại vô ý liên quan đến việc sử dụng công cụ AI.
    

## Các Loại Hại Từ AI Nếu Sử Dụng Không Có Trách Nhiệm

AI có thể gây hại nếu thiếu sự can thiệp của con người hoặc tư duy phê phán, dẫn đến củng cố thiên kiến hệ thống, phân bổ tài nguyên không công bằng, duy trì định kiến nguy hiểm hoặc tăng cường động lực quyền lực hiện có. Dưới đây là các loại hại chính:

- **Hại Phân Bổ (Allocative Harm)**: Xảy ra khi hệ thống AI từ chối cơ hội, tài nguyên hoặc thông tin trong lĩnh vực ảnh hưởng đến phúc lợi cá nhân.
    
    - Ví dụ: Nếu AI không cung cấp thông tin đồng đều, một số người có thể bị từ chối tiếp cận giáo dục, chăm sóc sức khỏe, nhà ở công bằng.
        
    - Trường hợp cụ thể: Quản lý bất động sản sử dụng AI để sàng lọc đơn thuê căn hộ dựa trên tên và thông tin nhận dạng để kiểm tra lý lịch. Một ứng viên bị từ chối do điểm tín dụng thấp và mất phí nộp đơn, nhưng sau đó phát hiện AI nhầm lẫn danh tính và kiểm tra sai người. Ứng viên chịu hại phân bổ vì mất cơ hội và tài nguyên, ảnh hưởng đến phúc lợi.
        
- **Hại Chất Lượng Dịch Vụ (Quality-of-Service Harm)**: Tình huống AI hoạt động kém hiệu quả hơn đối với một số nhóm người dựa trên đặc tính cá nhân.
    
    - Ví dụ: Công nghệ nhận diện giọng nói ban đầu thiếu dữ liệu huấn luyện về mẫu giọng nói của người khuyết tật, dẫn đến khó phân tích loại giọng này (công nghệ vẫn đang phát triển).
        
- **Hại Đại Diện (Representational Harm)**: AI củng cố sự hạ thấp các nhóm xã hội dựa trên đặc tính của họ.
    
    - Ví dụ: AI trong ứng dụng dịch ngôn ngữ có thể liên kết từ ngữ với đặc tính nữ tính hoặc nam tính, chọn bản dịch giới tính cụ thể dựa trên giả định. Điều này gây hại bằng cách xóa sổ hoặc loại trừ nhóm xã hội do thiên kiến tích hợp.
        
- **Hại Hệ Thống Xã Hội (Social System Harm)**: Tác động xã hội ở mức vĩ mô, khuếch đại sự chênh lệch giai cấp, quyền lực hoặc đặc quyền, hoặc gây hại vật lý từ phát triển/sử dụng AI.
    
    - Ví dụ: Với hình ảnh do AI tạo ngày càng chân thực, lo ngại về lan truyền thông tin sai lệch, bao gồm deepfake (deepfakes) – ảnh hoặc video giả mạo do AI tạo, cho thấy người thật nói hoặc làm điều họ không làm.
        
    - Trường hợp cụ thể: Deepfake của ứng cử viên hội đồng trường học cho thấy họ nói điều không đúng, lan truyền rộng gây thua cuộc bầu cử, ảnh hưởng đến quan điểm cử tri, cảm nhận của phụ huynh về khu học chánh và cộng đồng. Đây là hại hệ thống xã hội do thông tin sai lệch lan rộng quy mô lớn.
        
    - Giải pháp: Công nghệ mới phát hiện deepfake, như công cụ tạo hình ảnh thêm dấu nước kỹ thuật số để chỉ rõ nguồn gốc. Theo thời gian, máy tính sẽ dễ nhận diện deepfake hơn. Người dùng AI cần nhận thức khó khăn trong phân biệt hình ảnh AI và thật, cũng như hậu quả tạo deepfake.
        
- **Hại Liên Cá Nhân (Interpersonal Harm)**: Sử dụng công nghệ để tạo bất lợi cho một số người, ảnh hưởng tiêu cực đến mối quan hệ hoặc mất cảm giác tự chủ và bản ngã.
    
    - Ví dụ: Chia sẻ thông tin cá nhân với AI có thể bị lạm dụng, như khóa tài khoản trực tuyến hoặc giám sát ai đó.
        

## Kết Luận

- Tất cả các hại này minh họa cách sử dụng công nghệ không có trách nhiệm ảnh hưởng tiêu cực đến cá nhân và cộng đồng.
    
- Tin tốt là công cụ AI đang phát triển nhanh chóng dựa trên phản hồi từ người dùng.
    
- Nhận thức về hại tiềm ẩn và kết quả tiêu cực là bước đầu tiên để sử dụng AI có trách nhiệm.