## Các loại tác hại của AI và cách giảm thiểu

### Nhu cầu can thiệp của con người

**Để hạn chế thiên lệch, drift và độ không chính xác**, các mô hình AI yêu cầu con người thực hiện hành động:

- **Huấn luyện lại mô hình** (retraining models) trên các bộ dữ liệu đa dạng hơn
- **Tiếp tục tinh chỉnh** (fine-tune) chúng thường xuyên
- **Xem xét các tác hại vô ý** (inadvertent harms) liên quan đến việc sử dụng các công cụ AI


### Các loại tác hại của AI

#### 1. Tác hại phân bổ (Allocative Harm)

**Định nghĩa:** Hành vi sai trái xảy ra khi việc sử dụng hoặc hành vi của hệ thống AI từ chối cơ hội, tài nguyên hoặc thông tin trong các lĩnh vực ảnh hưởng đến phúc lợi của một người.

**Hậu quả:** Một số người có thể bị từ chối tiếp cận:

- Giáo dục (education)
- Chăm sóc sức khỏe (healthcare)
- Nhà ở công bằng (fair housing)
- Các cơ hội khác

**Ví dụ thực tế - Thuê nhà:**

- Quản lý bất động sản sử dụng công cụ AI để sàng lọc đơn xin thuê
- AI sử dụng tên và thông tin nhận dạng để kiểm tra lý lịch
- Một ứng viên bị đánh giá là rủi ro vì điểm tín dụng thấp → bị từ chối thuê và mất phí đăng ký
- Sau đó phát hiện phần mềm đã nhận dạng sai người và kiểm tra lý lịch nhầm người
- **Kết quả:** Ứng viên trải qua tác hại phân bổ vì bị từ chối cơ hội và mất tài nguyên


#### 2. Tác hại chất lượng dịch vụ (Quality-of-Service Harm)

**Định nghĩa:** Hoàn cảnh mà các công cụ AI không hoạt động tốt cho một số nhóm người nhất định dựa trên danh tính của họ.

**Ví dụ - Công nghệ nhận dạng giọng nói:**

- Khi công nghệ nhận dạng giọng nói lần đầu được phát triển
- Dữ liệu huấn luyện không có nhiều ví dụ về mẫu giọng nói của người khuyết tật
- Thiết bị thường gặp khó khăn trong việc phân tích loại giọng nói này
- **Lưu ý:** Công nghệ này vẫn đang phát triển


#### 3. Tác hại đại diện (Representational Harm)

**Định nghĩa:** Việc công cụ AI củng cố sự phụ thuộc của các nhóm xã hội dựa trên danh tính của họ.

**Ví dụ - Ứng dụng dịch thuật:**

- AI trong ứng dụng dịch ngôn ngữ có thể liên kết từ ngữ nhất định với đặc điểm nữ tính hoặc nam tính
- Chọn bản dịch cụ thể theo giới tính dựa trên những giả định đó
- **Tác hại:** Kết quả có thể xóa bỏ hoặc cách ly các nhóm xã hội do thiên lệch có sẵn


#### 4. Tác hại hệ thống xã hội (Social System Harm)

**Định nghĩa:** Các tác động cấp vĩ mô của xã hội làm khuếch đại sự khác biệt về giai cấp, quyền lực hoặc đặc quyền hiện có, hoặc gây tổn hại vật lý do phát triển hoặc sử dụng công cụ AI.

**Vấn đề Deepfakes:**

- **Deepfakes:** Ảnh hoặc video giả do AI tạo ra về người thật nói hoặc làm những việc họ không hề làm
- Khi ảnh do AI tạo ra trở nên chân thực hơn → lo ngại về việc lan truyền thông tin sai lệch (disinformation)

**Ví dụ cụ thể:**

- Deepfake về ứng cử viên hội đồng trường học cho thấy người đó nói điều họ không nói
- Nếu lan truyền, khiến họ thua cuộc bầu cử
- **Tác động:** Ảnh hưởng đến quan điểm của cử tri, cảm giác của phụ huynh về học khu và cộng đồng nói chung
- **Kết quả:** Thông tin sai lệch được lan truyền quy mô lớn = tác hại hệ thống xã hội

**Các biện pháp đối phó:**

- Công nghệ mới đang được tạo ra để phát hiện Deepfakes
- Một số công cụ tạo ảnh đang đặt watermark kỹ thuật số (digital watermarks) trên ảnh và video do AI tạo ra
- Theo thời gian, deepfakes sẽ trở nên dễ nhận dạng hơn bằng máy tính

**Trách nhiệm người dùng AI:**

- Nhận thức về khó khăn trong việc phân biệt ảnh do AI tạo ra và ảnh thật
- Hiểu hậu quả của việc tạo ra những deepfakes này


#### 5. Tác hại giữa các cá nhân (Interpersonal Harm)

**Định nghĩa:** Việc sử dụng công nghệ để tạo bất lợi cho một số người nhất định, ảnh hưởng tiêu cực đến mối quan hệ của họ với người khác hoặc gây mất ý thức về bản thân và quyền tự chủ.

**Ví dụ:**

- Mọi người có thể chia sẻ thông tin riêng tư với công cụ AI có thể bị lạm dụng bởi người khác
- Như khóa ai đó khỏi tài khoản trực tuyến hoặc giám sát họ


### Tổng kết và cảnh báo

**Tất cả các tác hại này là ví dụ** về cách sử dụng công nghệ một cách vô trách nhiệm có thể tác động tiêu cực đến con người và cộng đồng.

**Nếu sử dụng mà không có sự can thiệp của con người hoặc tư duy phản biện**, AI có thể:

- Củng cố thiên lệch hệ thống (systemic bias)
- Dẫn đến phân phối tài nguyên không công bằng
- Duy trì các định kiến nguy hiểm (dangerous stereotypes)
- Củng cố động lực quyền lực đang diễn ra (ongoing power dynamics)


### Tin tốt và hướng tương lai

**Các công cụ AI đang phát triển nhanh chóng** dựa trên phản hồi từ người dùng.

**Bước đầu tiên để sử dụng AI có trách nhiệm:** Nhận thức về tác hại tiềm ẩn và kết quả tiêu cực.

**Liên kết:** [[Allocative Harm]], [[Quality-of-Service Harm]], [[Representational Harm]], [[Social System Harm]], [[Interpersonal Harm]], [[Deepfakes]], [[Systemic Bias]], [[Responsible AI]], [[Digital Watermarks]], [[Disinformation]]

