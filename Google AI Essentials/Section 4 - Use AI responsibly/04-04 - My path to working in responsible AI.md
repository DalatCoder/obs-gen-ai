## Quan điểm từ chuyên gia: Emilio - Program Manager về Đổi mới có Trách nhiệm tại Google

### Giới thiệu về vai trò

**Emilio** - Chuyên gia quản lý chương trình đổi mới có trách nhiệm (Responsible Innovation Program Manager) tại Google

**Background học tập:**

- Chuyên ngành Khoa học Chính trị (Political Science)
- Chuyên ngành Tiếng Tây Ban Nha (Spanish)

**Mô tả công việc:**

- **"Tôi làm tất cả và không làm gì cả"** - Là một program manager
- Đảm bảo hoàn thành công việc đúng thời hạn
- Đảm bảo mọi người hợp tác tốt và hiệu quả
- **Kết nối các chuyên gia AI** với các nhóm phát triển sản phẩm:
    - Chuyên gia trong các lĩnh vực AI cụ thể như nhận thức (perception), công bằng (fairness)
    - Nhóm phát triển sản phẩm muốn tích hợp các thực hành tốt nhất


### Nhận thức về tác hại của AI

**Nguồn cảm hứng:** Đọc một cuốn sách có tác động mạnh về **nguy cơ tự động hóa một số cấp độ bất bình đẳng hệ thống** (automating systemic inequality)

**Quan điểm cân bằng:**

- **Techno-optimist** (tin tưởng vào công nghệ) - nhìn thấy khả năng của AI
- **Nhận thức rủi ro** - hiểu hậu quả của việc triển khai AI mà không dạy đầy đủ cho mọi người
- Cần hiểu rõ **hậu quả của các hệ thống này** (ramifications of these systems)


### Thiên lệch cá nhân và AI

#### Ví dụ về thiên lệch cá nhân

**Emilio đến từ Nam California:**

- Có thiên lệch hướng tới ánh nắng mặt trời và sóng biển hoàn hảo
- **"Tôi nghĩ nhiều người cũng vậy, nhưng tôi đặc biệt như vậy"**


#### Liên hệ với AI

**Các khía cạnh con người có thể không trực tiếp chuyển đổi được sang mô hình machine learning, nhưng:**

- **Có thể cân bằng trải nghiệm với dữ liệu** (equate experiences to data)
- **Mô hình machine learning chỉ có thể học** dựa trên dữ liệu mà chúng đã tiêu thụ:
    - Bộ dữ liệu lịch sử (historical data sets)
    - Phản hồi từ người dùng (user feedback)

**Mục tiêu:** Nếu có thể làm cho các hệ thống này **đại diện hơn cho những người dùng** mà chúng tuyên bố phục vụ → sẽ giúp phục vụ nhiều người hơn

### Câu hỏi quan trọng cần đặt ra

**Về dữ liệu:**

- **Thông tin nào** đang được đưa vào các bộ dữ liệu đó?
- **Ai được bao gồm** và **ai bị loại trừ**?

**Ví dụ cụ thể - Hệ thống phát hiện khuôn mặt (Facial Detection Systems):**

- Hệ thống hoạt động tốt như thế nào cho những người như Emilio - có làn da giàu melanin hơn (melanin-rich skin)?
- Hoạt động thế nào với những người có làn da **thậm chí giàu melanin hơn**?
- **Liệu nó có hoạt động bình đẳng** trên toàn phổ không?
- **Liệu nó có không hoạt động bình đẳng** trên toàn phổ không?


### Trách nhiệm cá nhân khi sử dụng AI

**"Tôi nghĩ tất cả chúng ta đều có trách nhiệm cá nhân khi sử dụng những công cụ này"**

#### Hai điều quan trọng có thể làm:

**1. Kiểm tra đầu ra (Check the outputs):**

- Kiểm tra kết quả của bất kỳ công cụ nào bạn đang sử dụng

**2. Kiểm tra dữ liệu đầu vào:**

- Nếu bạn sử dụng dữ liệu mới được đưa vào mô hình, hãy kiểm tra dữ liệu đó
- **Đảm bảo tính bao gồm** (inclusive)
- **Đảm bảo tính đại diện** cho các cộng đồng khác nhau mà bạn hy vọng tương tác


#### Tham gia tích cực:

**Liên tục đưa ra phản hồi về:**

- Những điều bạn **không tán thành**
- Những điều bạn **tán thành**

**Mục đích:** Để các nhóm tạo ra những hệ thống này biết cách cải thiện

### Thông điệp chính

**AI phản ánh background và values của những người tạo ra nó**, giống như con người phản ánh trải nghiệm và văn hóa của mình.

**Giải pháp:** Tạo ra các hệ thống **đại diện và bao gồm** nhiều cộng đồng khác nhau thông qua:

- Dữ liệu đa dạng
- Phản hồi tích cực từ người dùng
- Kiểm tra và giám sát liên tục

**Liên kết:** [[Responsible Innovation]], [[Program Manager]], [[Systemic Inequality]], [[Techno-optimist]], [[Machine Learning]], [[Facial Detection Systems]], [[Melanin-rich Skin]], [[Data Bias]], [[User Feedback]], [[Inclusive AI]], [[Representative AI]]

